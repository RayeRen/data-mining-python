{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from softmax_loss import softmax_loss\n",
    "from feedforward_backprop import feedforward_backprop\n",
    "from utils import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('data/digit_data.mat')\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "num_cases = X.shape[1]\n",
    "train_num_cases = num_cases * 4 // 5\n",
    "X = X.reshape([400, num_cases])\n",
    "X = np.transpose(X, [1, 0])\n",
    "# X has the shape of [number of samples, number of pixels]\n",
    "train_data = X[:train_num_cases]\n",
    "train_label = y[:, :train_num_cases]\n",
    "test_data = X[train_num_cases:]\n",
    "test_label = y[:, train_num_cases:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00e+00, 0.00e+00, 0.00e+00\n",
      "1.48e-02, 1.48e-02, 1.48e-02\n",
      "1.75e-02, 1.75e-02, 1.75e-02\n",
      "4.60e-03, 4.60e-03, 4.60e-03\n",
      "3.19e-02, 3.19e-02, 3.19e-02\n",
      "0.00e+00, 0.00e+00, 0.00e+00\n",
      "0.00e+00, 0.00e+00, 0.00e+00\n",
      "0.00e+00, 0.00e+00, 0.00e+00\n",
      "0.00e+00, 0.00e+00, 0.00e+00\n",
      "0.00e+00, 0.00e+00, 0.00e+00\n",
      "0.00e+00, 0.00e+00, 0.00e+00\n",
      "7.90e-03, 7.90e-03, 7.90e-03\n",
      "0.00e+00, 0.00e+00, 0.00e+00\n",
      "2.25e-02, 2.25e-02, 2.25e-02\n",
      "0.00e+00, 0.00e+00, 0.00e+00\n",
      "0.00e+00, 0.00e+00, 0.00e+00\n",
      "0.00e+00, 0.00e+00, 0.00e+00\n",
      "8.46e-03, 8.46e-03, 8.46e-03\n",
      "0.00e+00, 0.00e+00, 0.00e+00\n",
      "0.00e+00, 0.00e+00, 0.00e+00\n",
      "2.27e-02, 2.27e-02, 2.27e-02\n",
      "0.00e+00, 0.00e+00, 0.00e+00\n",
      "0.00e+00, 0.00e+00, 0.00e+00\n",
      "1.38e-02, 1.38e-02, 1.38e-02\n",
      "0.00e+00, 0.00e+00, 0.00e+00\n"
     ]
    }
   ],
   "source": [
    "weights = {}\n",
    "weights['fully1_weight'] = np.random.randn(400, 25) / 400\n",
    "weights['fully1_bias'] = np.random.randn(25, 1)\n",
    "weights['fully2_weight'] = np.random.randn(25, 10) / 25\n",
    "weights['fully2_bias'] = np.random.randn(10, 1)\n",
    "\n",
    "fully1_weight_inc = np.zeros_like(weights['fully1_weight'])\n",
    "fully1_bias_inc = np.zeros_like(weights['fully1_bias'])\n",
    "fully2_weight_inc = np.zeros_like(weights['fully2_weight'])\n",
    "fully2_bias_inc = np.zeros_like(weights['fully2_bias'])\n",
    "\n",
    "EPSILON = 0.00010;\n",
    "\n",
    "X = train_data[:100]\n",
    "y = train_label[:, :100]\n",
    "# The feedforward and backpropgation processes.\n",
    "loss, _, gradients = feedforward_backprop(X, y, weights)\n",
    "\n",
    "# check correctness of fully1_bias's gradient\n",
    "for c in range(weights['fully1_bias'].shape[0]):\n",
    "    weights['fully1_bias'][c, 0] = weights['fully1_bias'][c, 0] + EPSILON\n",
    "    loss_2, _, gradients_2 = feedforward_backprop(X, y, weights)\n",
    "    print('%.2e, %.2e, %.2e'%((loss_2 - loss) / EPSILON, gradients['fully1_bias_grad'][c, 0], gradients_2['fully1_bias_grad'][c, 0]))\n",
    "    weights['fully1_bias'][c, 0]=weights['fully1_bias'][c, 0] - EPSILON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000.00 loss:2.742e+00, accuracy:0.070000\n",
      "000.01 loss:2.588e+00, accuracy:0.120000\n",
      "000.02 loss:2.456e+00, accuracy:0.070000\n",
      "000.03 loss:2.361e+00, accuracy:0.150000\n",
      "000.04 loss:2.303e+00, accuracy:0.110000\n",
      "000.05 loss:2.343e+00, accuracy:0.100000\n",
      "000.06 loss:2.339e+00, accuracy:0.120000\n",
      "000.07 loss:2.305e+00, accuracy:0.130000\n",
      "000.08 loss:2.198e+00, accuracy:0.150000\n",
      "000.09 loss:2.133e+00, accuracy:0.290000\n",
      "000.10 loss:2.166e+00, accuracy:0.260000\n",
      "000.11 loss:2.102e+00, accuracy:0.290000\n",
      "000.12 loss:2.174e+00, accuracy:0.260000\n",
      "000.13 loss:2.170e+00, accuracy:0.210000\n",
      "000.14 loss:2.052e+00, accuracy:0.210000\n",
      "000.15 loss:2.074e+00, accuracy:0.210000\n",
      "000.16 loss:2.014e+00, accuracy:0.240000\n",
      "000.17 loss:1.975e+00, accuracy:0.370000\n",
      "000.18 loss:1.900e+00, accuracy:0.350000\n",
      "000.19 loss:1.827e+00, accuracy:0.350000\n",
      "000.20 loss:1.781e+00, accuracy:0.420000\n",
      "000.21 loss:1.789e+00, accuracy:0.420000\n",
      "000.22 loss:1.622e+00, accuracy:0.530000\n",
      "000.23 loss:1.610e+00, accuracy:0.520000\n",
      "000.24 loss:1.477e+00, accuracy:0.630000\n",
      "000.25 loss:1.355e+00, accuracy:0.700000\n",
      "000.26 loss:1.352e+00, accuracy:0.550000\n",
      "000.27 loss:1.270e+00, accuracy:0.660000\n",
      "000.28 loss:1.216e+00, accuracy:0.680000\n",
      "000.29 loss:1.192e+00, accuracy:0.640000\n",
      "000.30 loss:1.098e+00, accuracy:0.730000\n",
      "000.31 loss:1.066e+00, accuracy:0.670000\n",
      "000.32 loss:9.564e-01, accuracy:0.710000\n",
      "000.33 loss:9.926e-01, accuracy:0.720000\n",
      "000.34 loss:9.204e-01, accuracy:0.720000\n",
      "000.35 loss:9.488e-01, accuracy:0.610000\n",
      "000.36 loss:7.522e-01, accuracy:0.750000\n",
      "000.37 loss:7.922e-01, accuracy:0.750000\n",
      "000.38 loss:6.399e-01, accuracy:0.830000\n",
      "000.39 loss:7.349e-01, accuracy:0.790000\n",
      "001.00 loss:7.646e-01, accuracy:0.720000\n",
      "001.01 loss:6.939e-01, accuracy:0.770000\n",
      "001.02 loss:4.984e-01, accuracy:0.860000\n",
      "001.03 loss:6.934e-01, accuracy:0.790000\n",
      "001.04 loss:6.350e-01, accuracy:0.740000\n",
      "001.05 loss:4.161e-01, accuracy:0.880000\n",
      "001.06 loss:6.122e-01, accuracy:0.830000\n",
      "001.07 loss:4.598e-01, accuracy:0.870000\n",
      "001.08 loss:4.591e-01, accuracy:0.860000\n",
      "001.09 loss:5.708e-01, accuracy:0.830000\n",
      "001.10 loss:5.511e-01, accuracy:0.800000\n",
      "001.11 loss:7.333e-01, accuracy:0.830000\n",
      "001.12 loss:6.181e-01, accuracy:0.750000\n",
      "001.13 loss:6.931e-01, accuracy:0.780000\n",
      "001.14 loss:3.398e-01, accuracy:0.890000\n",
      "001.15 loss:4.888e-01, accuracy:0.880000\n",
      "001.16 loss:5.967e-01, accuracy:0.780000\n",
      "001.17 loss:6.327e-01, accuracy:0.850000\n",
      "001.18 loss:5.819e-01, accuracy:0.830000\n",
      "001.19 loss:3.492e-01, accuracy:0.900000\n",
      "001.20 loss:4.027e-01, accuracy:0.870000\n",
      "001.21 loss:5.761e-01, accuracy:0.800000\n",
      "001.22 loss:4.755e-01, accuracy:0.820000\n",
      "001.23 loss:4.721e-01, accuracy:0.860000\n",
      "001.24 loss:3.347e-01, accuracy:0.940000\n",
      "001.25 loss:4.260e-01, accuracy:0.910000\n",
      "001.26 loss:5.781e-01, accuracy:0.790000\n",
      "001.27 loss:5.463e-01, accuracy:0.840000\n",
      "001.28 loss:4.025e-01, accuracy:0.840000\n",
      "001.29 loss:4.005e-01, accuracy:0.860000\n",
      "001.30 loss:4.819e-01, accuracy:0.880000\n",
      "001.31 loss:5.677e-01, accuracy:0.790000\n",
      "001.32 loss:4.001e-01, accuracy:0.890000\n",
      "001.33 loss:4.491e-01, accuracy:0.880000\n",
      "001.34 loss:6.136e-01, accuracy:0.850000\n",
      "001.35 loss:5.080e-01, accuracy:0.880000\n",
      "001.36 loss:3.073e-01, accuracy:0.920000\n",
      "001.37 loss:4.520e-01, accuracy:0.870000\n",
      "001.38 loss:3.442e-01, accuracy:0.910000\n",
      "001.39 loss:4.751e-01, accuracy:0.880000\n",
      "002.00 loss:3.415e-01, accuracy:0.900000\n",
      "002.01 loss:5.152e-01, accuracy:0.850000\n",
      "002.02 loss:2.675e-01, accuracy:0.930000\n",
      "002.03 loss:4.343e-01, accuracy:0.890000\n",
      "002.04 loss:3.635e-01, accuracy:0.890000\n",
      "002.05 loss:2.271e-01, accuracy:0.950000\n",
      "002.06 loss:4.357e-01, accuracy:0.880000\n",
      "002.07 loss:2.786e-01, accuracy:0.940000\n",
      "002.08 loss:2.475e-01, accuracy:0.940000\n",
      "002.09 loss:4.503e-01, accuracy:0.920000\n",
      "002.10 loss:3.548e-01, accuracy:0.850000\n",
      "002.11 loss:5.733e-01, accuracy:0.850000\n",
      "002.12 loss:5.420e-01, accuracy:0.810000\n",
      "002.13 loss:4.642e-01, accuracy:0.890000\n",
      "002.14 loss:2.127e-01, accuracy:0.930000\n",
      "002.15 loss:2.964e-01, accuracy:0.930000\n",
      "002.16 loss:4.415e-01, accuracy:0.830000\n",
      "002.17 loss:6.008e-01, accuracy:0.840000\n",
      "002.18 loss:4.936e-01, accuracy:0.830000\n",
      "002.19 loss:3.296e-01, accuracy:0.860000\n",
      "002.20 loss:2.865e-01, accuracy:0.900000\n",
      "002.21 loss:4.223e-01, accuracy:0.880000\n",
      "002.22 loss:4.385e-01, accuracy:0.880000\n",
      "002.23 loss:3.071e-01, accuracy:0.900000\n",
      "002.24 loss:2.679e-01, accuracy:0.950000\n",
      "002.25 loss:3.006e-01, accuracy:0.910000\n",
      "002.26 loss:4.281e-01, accuracy:0.890000\n",
      "002.27 loss:4.116e-01, accuracy:0.890000\n",
      "002.28 loss:3.575e-01, accuracy:0.880000\n",
      "002.29 loss:3.466e-01, accuracy:0.900000\n",
      "002.30 loss:4.290e-01, accuracy:0.870000\n",
      "002.31 loss:3.490e-01, accuracy:0.880000\n",
      "002.32 loss:3.677e-01, accuracy:0.890000\n",
      "002.33 loss:3.566e-01, accuracy:0.890000\n",
      "002.34 loss:4.433e-01, accuracy:0.910000\n",
      "002.35 loss:3.637e-01, accuracy:0.900000\n",
      "002.36 loss:2.320e-01, accuracy:0.920000\n",
      "002.37 loss:3.538e-01, accuracy:0.920000\n",
      "002.38 loss:2.702e-01, accuracy:0.930000\n",
      "002.39 loss:4.359e-01, accuracy:0.910000\n",
      "003.00 loss:2.609e-01, accuracy:0.920000\n",
      "003.01 loss:3.960e-01, accuracy:0.890000\n",
      "003.02 loss:2.179e-01, accuracy:0.960000\n",
      "003.03 loss:3.560e-01, accuracy:0.930000\n",
      "003.04 loss:2.955e-01, accuracy:0.930000\n",
      "003.05 loss:1.787e-01, accuracy:0.950000\n",
      "003.06 loss:4.591e-01, accuracy:0.880000\n",
      "003.07 loss:2.455e-01, accuracy:0.940000\n",
      "003.08 loss:1.956e-01, accuracy:0.960000\n",
      "003.09 loss:3.942e-01, accuracy:0.900000\n",
      "003.10 loss:3.143e-01, accuracy:0.870000\n",
      "003.11 loss:5.042e-01, accuracy:0.880000\n",
      "003.12 loss:4.894e-01, accuracy:0.850000\n",
      "003.13 loss:4.462e-01, accuracy:0.870000\n",
      "003.14 loss:2.032e-01, accuracy:0.920000\n",
      "003.15 loss:2.786e-01, accuracy:0.920000\n",
      "003.16 loss:3.322e-01, accuracy:0.890000\n",
      "003.17 loss:4.924e-01, accuracy:0.880000\n",
      "003.18 loss:4.590e-01, accuracy:0.830000\n",
      "003.19 loss:2.899e-01, accuracy:0.890000\n",
      "003.20 loss:2.951e-01, accuracy:0.890000\n",
      "003.21 loss:3.229e-01, accuracy:0.890000\n",
      "003.22 loss:3.344e-01, accuracy:0.920000\n",
      "003.23 loss:2.548e-01, accuracy:0.930000\n",
      "003.24 loss:2.441e-01, accuracy:0.960000\n",
      "003.25 loss:2.802e-01, accuracy:0.910000\n",
      "003.26 loss:4.061e-01, accuracy:0.880000\n",
      "003.27 loss:3.139e-01, accuracy:0.920000\n",
      "003.28 loss:3.082e-01, accuracy:0.930000\n",
      "003.29 loss:2.519e-01, accuracy:0.930000\n",
      "003.30 loss:3.786e-01, accuracy:0.880000\n",
      "003.31 loss:2.352e-01, accuracy:0.930000\n",
      "003.32 loss:2.980e-01, accuracy:0.900000\n",
      "003.33 loss:3.057e-01, accuracy:0.910000\n",
      "003.34 loss:4.074e-01, accuracy:0.920000\n",
      "003.35 loss:3.257e-01, accuracy:0.920000\n",
      "003.36 loss:2.408e-01, accuracy:0.930000\n",
      "003.37 loss:2.983e-01, accuracy:0.900000\n",
      "003.38 loss:2.489e-01, accuracy:0.930000\n",
      "003.39 loss:4.198e-01, accuracy:0.900000\n",
      "004.00 loss:2.159e-01, accuracy:0.940000\n",
      "004.01 loss:3.132e-01, accuracy:0.890000\n",
      "004.02 loss:2.070e-01, accuracy:0.930000\n",
      "004.03 loss:3.904e-01, accuracy:0.900000\n",
      "004.04 loss:2.561e-01, accuracy:0.920000\n",
      "004.05 loss:1.603e-01, accuracy:0.930000\n",
      "004.06 loss:4.271e-01, accuracy:0.870000\n",
      "004.07 loss:2.176e-01, accuracy:0.960000\n",
      "004.08 loss:1.932e-01, accuracy:0.950000\n",
      "004.09 loss:3.218e-01, accuracy:0.910000\n",
      "004.10 loss:2.698e-01, accuracy:0.910000\n",
      "004.11 loss:3.883e-01, accuracy:0.920000\n",
      "004.12 loss:4.094e-01, accuracy:0.880000\n",
      "004.13 loss:4.426e-01, accuracy:0.850000\n",
      "004.14 loss:1.935e-01, accuracy:0.920000\n",
      "004.15 loss:2.654e-01, accuracy:0.940000\n",
      "004.16 loss:2.840e-01, accuracy:0.900000\n",
      "004.17 loss:4.115e-01, accuracy:0.890000\n",
      "004.18 loss:4.018e-01, accuracy:0.880000\n",
      "004.19 loss:2.450e-01, accuracy:0.910000\n",
      "004.20 loss:2.848e-01, accuracy:0.910000\n",
      "004.21 loss:2.528e-01, accuracy:0.910000\n",
      "004.22 loss:2.862e-01, accuracy:0.920000\n",
      "004.23 loss:2.314e-01, accuracy:0.920000\n",
      "004.24 loss:1.996e-01, accuracy:0.960000\n",
      "004.25 loss:2.217e-01, accuracy:0.910000\n",
      "004.26 loss:3.597e-01, accuracy:0.900000\n",
      "004.27 loss:2.898e-01, accuracy:0.910000\n",
      "004.28 loss:2.844e-01, accuracy:0.930000\n",
      "004.29 loss:1.933e-01, accuracy:0.950000\n",
      "004.30 loss:2.637e-01, accuracy:0.920000\n",
      "004.31 loss:1.749e-01, accuracy:0.960000\n",
      "004.32 loss:2.491e-01, accuracy:0.920000\n",
      "004.33 loss:2.597e-01, accuracy:0.940000\n",
      "004.34 loss:3.934e-01, accuracy:0.920000\n",
      "004.35 loss:3.286e-01, accuracy:0.900000\n",
      "004.36 loss:2.022e-01, accuracy:0.940000\n",
      "004.37 loss:2.777e-01, accuracy:0.920000\n",
      "004.38 loss:2.294e-01, accuracy:0.940000\n",
      "004.39 loss:3.795e-01, accuracy:0.910000\n",
      "005.00 loss:1.962e-01, accuracy:0.940000\n",
      "005.01 loss:2.380e-01, accuracy:0.910000\n",
      "005.02 loss:1.702e-01, accuracy:0.940000\n",
      "005.03 loss:3.402e-01, accuracy:0.910000\n",
      "005.04 loss:2.143e-01, accuracy:0.930000\n",
      "005.05 loss:1.376e-01, accuracy:0.980000\n",
      "005.06 loss:3.884e-01, accuracy:0.880000\n",
      "005.07 loss:1.923e-01, accuracy:0.960000\n",
      "005.08 loss:1.852e-01, accuracy:0.950000\n",
      "005.09 loss:2.758e-01, accuracy:0.910000\n",
      "005.10 loss:2.633e-01, accuracy:0.900000\n",
      "005.11 loss:3.317e-01, accuracy:0.940000\n",
      "005.12 loss:3.380e-01, accuracy:0.900000\n",
      "005.13 loss:3.774e-01, accuracy:0.890000\n",
      "005.14 loss:1.601e-01, accuracy:0.940000\n",
      "005.15 loss:2.538e-01, accuracy:0.940000\n",
      "005.16 loss:2.470e-01, accuracy:0.920000\n",
      "005.17 loss:3.706e-01, accuracy:0.920000\n",
      "005.18 loss:3.791e-01, accuracy:0.880000\n",
      "005.19 loss:2.170e-01, accuracy:0.940000\n",
      "005.20 loss:2.484e-01, accuracy:0.910000\n",
      "005.21 loss:2.186e-01, accuracy:0.910000\n",
      "005.22 loss:2.359e-01, accuracy:0.950000\n",
      "005.23 loss:2.120e-01, accuracy:0.930000\n",
      "005.24 loss:1.885e-01, accuracy:0.960000\n",
      "005.25 loss:1.904e-01, accuracy:0.930000\n",
      "005.26 loss:3.101e-01, accuracy:0.900000\n",
      "005.27 loss:2.469e-01, accuracy:0.960000\n",
      "005.28 loss:2.650e-01, accuracy:0.930000\n",
      "005.29 loss:1.573e-01, accuracy:0.960000\n",
      "005.30 loss:2.333e-01, accuracy:0.930000\n",
      "005.31 loss:1.520e-01, accuracy:0.980000\n",
      "005.32 loss:2.453e-01, accuracy:0.940000\n",
      "005.33 loss:2.466e-01, accuracy:0.940000\n",
      "005.34 loss:3.737e-01, accuracy:0.910000\n",
      "005.35 loss:3.108e-01, accuracy:0.890000\n",
      "005.36 loss:1.856e-01, accuracy:0.950000\n",
      "005.37 loss:2.515e-01, accuracy:0.930000\n",
      "005.38 loss:2.116e-01, accuracy:0.950000\n",
      "005.39 loss:3.439e-01, accuracy:0.900000\n",
      "006.00 loss:2.045e-01, accuracy:0.940000\n",
      "006.01 loss:2.219e-01, accuracy:0.940000\n",
      "006.02 loss:1.645e-01, accuracy:0.940000\n",
      "006.03 loss:2.892e-01, accuracy:0.910000\n",
      "006.04 loss:1.939e-01, accuracy:0.950000\n",
      "006.05 loss:1.387e-01, accuracy:0.960000\n",
      "006.06 loss:3.527e-01, accuracy:0.880000\n",
      "006.07 loss:1.787e-01, accuracy:0.960000\n",
      "006.08 loss:1.563e-01, accuracy:0.970000\n",
      "006.09 loss:2.350e-01, accuracy:0.930000\n",
      "006.10 loss:2.379e-01, accuracy:0.900000\n",
      "006.11 loss:3.151e-01, accuracy:0.940000\n",
      "006.12 loss:3.056e-01, accuracy:0.890000\n",
      "006.13 loss:3.574e-01, accuracy:0.900000\n",
      "006.14 loss:1.231e-01, accuracy:0.950000\n",
      "006.15 loss:2.291e-01, accuracy:0.940000\n",
      "006.16 loss:2.099e-01, accuracy:0.920000\n",
      "006.17 loss:3.416e-01, accuracy:0.920000\n",
      "006.18 loss:3.931e-01, accuracy:0.890000\n",
      "006.19 loss:1.920e-01, accuracy:0.930000\n",
      "006.20 loss:2.215e-01, accuracy:0.930000\n",
      "006.21 loss:2.007e-01, accuracy:0.920000\n",
      "006.22 loss:2.113e-01, accuracy:0.970000\n",
      "006.23 loss:1.784e-01, accuracy:0.950000\n",
      "006.24 loss:1.804e-01, accuracy:0.960000\n",
      "006.25 loss:1.698e-01, accuracy:0.940000\n",
      "006.26 loss:2.566e-01, accuracy:0.920000\n",
      "006.27 loss:2.146e-01, accuracy:0.950000\n",
      "006.28 loss:2.418e-01, accuracy:0.950000\n",
      "006.29 loss:1.425e-01, accuracy:0.970000\n",
      "006.30 loss:2.222e-01, accuracy:0.930000\n",
      "006.31 loss:1.320e-01, accuracy:0.980000\n",
      "006.32 loss:2.253e-01, accuracy:0.940000\n",
      "006.33 loss:2.299e-01, accuracy:0.940000\n",
      "006.34 loss:3.570e-01, accuracy:0.900000\n",
      "006.35 loss:2.869e-01, accuracy:0.900000\n",
      "006.36 loss:1.724e-01, accuracy:0.960000\n",
      "006.37 loss:2.187e-01, accuracy:0.940000\n",
      "006.38 loss:2.079e-01, accuracy:0.950000\n",
      "006.39 loss:3.115e-01, accuracy:0.900000\n",
      "007.00 loss:1.768e-01, accuracy:0.940000\n",
      "007.01 loss:2.143e-01, accuracy:0.940000\n",
      "007.02 loss:1.490e-01, accuracy:0.950000\n",
      "007.03 loss:2.572e-01, accuracy:0.940000\n",
      "007.04 loss:1.841e-01, accuracy:0.940000\n",
      "007.05 loss:1.402e-01, accuracy:0.960000\n",
      "007.06 loss:3.343e-01, accuracy:0.880000\n",
      "007.07 loss:1.591e-01, accuracy:0.960000\n",
      "007.08 loss:1.322e-01, accuracy:0.980000\n",
      "007.09 loss:2.063e-01, accuracy:0.920000\n",
      "007.10 loss:2.274e-01, accuracy:0.910000\n",
      "007.11 loss:2.898e-01, accuracy:0.940000\n",
      "007.12 loss:2.934e-01, accuracy:0.900000\n",
      "007.13 loss:3.480e-01, accuracy:0.900000\n",
      "007.14 loss:1.057e-01, accuracy:0.980000\n",
      "007.15 loss:2.058e-01, accuracy:0.950000\n",
      "007.16 loss:1.710e-01, accuracy:0.940000\n",
      "007.17 loss:3.113e-01, accuracy:0.930000\n",
      "007.18 loss:3.676e-01, accuracy:0.890000\n",
      "007.19 loss:1.701e-01, accuracy:0.940000\n",
      "007.20 loss:1.959e-01, accuracy:0.940000\n",
      "007.21 loss:1.826e-01, accuracy:0.940000\n",
      "007.22 loss:1.976e-01, accuracy:0.960000\n",
      "007.23 loss:1.641e-01, accuracy:0.950000\n",
      "007.24 loss:1.575e-01, accuracy:0.970000\n",
      "007.25 loss:1.573e-01, accuracy:0.950000\n",
      "007.26 loss:2.310e-01, accuracy:0.940000\n",
      "007.27 loss:1.947e-01, accuracy:0.960000\n",
      "007.28 loss:2.142e-01, accuracy:0.950000\n",
      "007.29 loss:1.240e-01, accuracy:0.970000\n",
      "007.30 loss:2.049e-01, accuracy:0.950000\n",
      "007.31 loss:1.294e-01, accuracy:0.970000\n",
      "007.32 loss:2.215e-01, accuracy:0.930000\n",
      "007.33 loss:2.220e-01, accuracy:0.940000\n",
      "007.34 loss:3.462e-01, accuracy:0.910000\n",
      "007.35 loss:2.630e-01, accuracy:0.920000\n",
      "007.36 loss:1.476e-01, accuracy:0.960000\n",
      "007.37 loss:2.076e-01, accuracy:0.950000\n",
      "007.38 loss:1.826e-01, accuracy:0.950000\n",
      "007.39 loss:2.888e-01, accuracy:0.910000\n",
      "008.00 loss:1.617e-01, accuracy:0.930000\n",
      "008.01 loss:2.077e-01, accuracy:0.940000\n",
      "008.02 loss:1.404e-01, accuracy:0.950000\n",
      "008.03 loss:2.359e-01, accuracy:0.950000\n",
      "008.04 loss:1.737e-01, accuracy:0.940000\n",
      "008.05 loss:1.208e-01, accuracy:0.970000\n",
      "008.06 loss:3.004e-01, accuracy:0.900000\n",
      "008.07 loss:1.534e-01, accuracy:0.960000\n",
      "008.08 loss:1.196e-01, accuracy:0.980000\n",
      "008.09 loss:1.950e-01, accuracy:0.940000\n",
      "008.10 loss:2.110e-01, accuracy:0.920000\n",
      "008.11 loss:2.611e-01, accuracy:0.940000\n",
      "008.12 loss:2.675e-01, accuracy:0.890000\n",
      "008.13 loss:3.395e-01, accuracy:0.910000\n",
      "008.14 loss:9.536e-02, accuracy:0.990000\n",
      "008.15 loss:1.892e-01, accuracy:0.960000\n",
      "008.16 loss:1.491e-01, accuracy:0.940000\n",
      "008.17 loss:2.886e-01, accuracy:0.930000\n",
      "008.18 loss:3.396e-01, accuracy:0.890000\n",
      "008.19 loss:1.590e-01, accuracy:0.930000\n",
      "008.20 loss:1.860e-01, accuracy:0.940000\n",
      "008.21 loss:1.634e-01, accuracy:0.960000\n",
      "008.22 loss:1.926e-01, accuracy:0.950000\n",
      "008.23 loss:1.530e-01, accuracy:0.950000\n",
      "008.24 loss:1.487e-01, accuracy:0.970000\n",
      "008.25 loss:1.420e-01, accuracy:0.970000\n",
      "008.26 loss:2.229e-01, accuracy:0.950000\n",
      "008.27 loss:1.846e-01, accuracy:0.960000\n",
      "008.28 loss:2.026e-01, accuracy:0.950000\n",
      "008.29 loss:1.129e-01, accuracy:0.970000\n",
      "008.30 loss:2.020e-01, accuracy:0.950000\n",
      "008.31 loss:1.277e-01, accuracy:0.970000\n",
      "008.32 loss:2.146e-01, accuracy:0.940000\n",
      "008.33 loss:2.113e-01, accuracy:0.940000\n",
      "008.34 loss:3.451e-01, accuracy:0.900000\n",
      "008.35 loss:2.419e-01, accuracy:0.940000\n",
      "008.36 loss:1.375e-01, accuracy:0.960000\n",
      "008.37 loss:2.017e-01, accuracy:0.950000\n",
      "008.38 loss:1.756e-01, accuracy:0.950000\n",
      "008.39 loss:2.728e-01, accuracy:0.920000\n",
      "009.00 loss:1.498e-01, accuracy:0.940000\n",
      "009.01 loss:2.033e-01, accuracy:0.940000\n",
      "009.02 loss:1.284e-01, accuracy:0.970000\n",
      "009.03 loss:2.216e-01, accuracy:0.960000\n",
      "009.04 loss:1.741e-01, accuracy:0.940000\n",
      "009.05 loss:1.091e-01, accuracy:0.980000\n",
      "009.06 loss:2.746e-01, accuracy:0.900000\n",
      "009.07 loss:1.437e-01, accuracy:0.970000\n",
      "009.08 loss:1.167e-01, accuracy:0.980000\n",
      "009.09 loss:2.012e-01, accuracy:0.940000\n",
      "009.10 loss:2.076e-01, accuracy:0.930000\n",
      "009.11 loss:2.478e-01, accuracy:0.950000\n",
      "009.12 loss:2.387e-01, accuracy:0.900000\n",
      "009.13 loss:3.173e-01, accuracy:0.920000\n",
      "009.14 loss:8.754e-02, accuracy:0.990000\n",
      "009.15 loss:1.779e-01, accuracy:0.960000\n",
      "009.16 loss:1.293e-01, accuracy:0.950000\n",
      "009.17 loss:2.640e-01, accuracy:0.930000\n",
      "009.18 loss:3.305e-01, accuracy:0.890000\n",
      "009.19 loss:1.536e-01, accuracy:0.950000\n",
      "009.20 loss:1.599e-01, accuracy:0.950000\n",
      "009.21 loss:1.533e-01, accuracy:0.950000\n",
      "009.22 loss:1.804e-01, accuracy:0.960000\n",
      "009.23 loss:1.408e-01, accuracy:0.950000\n",
      "009.24 loss:1.382e-01, accuracy:0.970000\n",
      "009.25 loss:1.268e-01, accuracy:0.970000\n",
      "009.26 loss:1.988e-01, accuracy:0.960000\n",
      "009.27 loss:1.668e-01, accuracy:0.970000\n",
      "009.28 loss:1.932e-01, accuracy:0.960000\n",
      "009.29 loss:1.009e-01, accuracy:0.980000\n",
      "009.30 loss:1.905e-01, accuracy:0.960000\n",
      "009.31 loss:1.279e-01, accuracy:0.970000\n",
      "009.32 loss:2.167e-01, accuracy:0.920000\n",
      "009.33 loss:1.949e-01, accuracy:0.950000\n",
      "009.34 loss:3.271e-01, accuracy:0.900000\n",
      "009.35 loss:2.133e-01, accuracy:0.940000\n",
      "009.36 loss:1.366e-01, accuracy:0.950000\n",
      "009.37 loss:1.977e-01, accuracy:0.950000\n",
      "009.38 loss:1.616e-01, accuracy:0.950000\n",
      "009.39 loss:2.458e-01, accuracy:0.920000\n"
     ]
    }
   ],
   "source": [
    "weights = {}\n",
    "weights['fully1_weight'] = np.random.randn(400, 25) / 400\n",
    "weights['fully1_bias'] = np.random.randn(25, 1)\n",
    "weights['fully2_weight'] = np.random.randn(25, 10) / 25\n",
    "weights['fully2_bias'] = np.random.randn(10, 1)\n",
    "\n",
    "fully1_weight_inc = np.zeros_like(weights['fully1_weight'])\n",
    "fully1_bias_inc = np.zeros_like(weights['fully1_bias'])\n",
    "fully2_weight_inc = np.zeros_like(weights['fully2_weight'])\n",
    "fully2_bias_inc = np.zeros_like(weights['fully2_bias'])\n",
    "\n",
    "batch_size = 100\n",
    "max_epoch = 10\n",
    "momW = 0.9\n",
    "wc = 0.0005\n",
    "learning_rate = 0.1\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for i in range(int(np.ceil(train_num_cases / batch_size))):\n",
    "        X_train = train_data[i * batch_size: (i + 1) * batch_size]\n",
    "        y_train = train_label[:, i * batch_size: (i + 1) * batch_size]\n",
    "        # The feedforward and backpropgation processes.\n",
    "        loss, accuracy, gradients = feedforward_backprop(\n",
    "            X_train, y_train, weights)\n",
    "        print('%03d.%02d loss:%0.3e, accuracy:%f' % (epoch, i, loss, accuracy))\n",
    "\n",
    "        # Updating weights\n",
    "        fully1_weight_inc = get_new_weight_inc(\n",
    "            fully1_weight_inc, weights['fully1_weight'], momW, wc, learning_rate, gradients['fully1_weight_grad'])\n",
    "        weights['fully1_weight'] = weights['fully1_weight'] + fully1_weight_inc\n",
    "        fully1_bias_inc = get_new_weight_inc(\n",
    "            fully1_bias_inc, weights['fully1_bias'], momW, wc, learning_rate, gradients['fully1_bias_grad'])\n",
    "        weights['fully1_bias'] = weights['fully1_bias'] + fully1_bias_inc\n",
    "\n",
    "        fully2_weight_inc = get_new_weight_inc(\n",
    "            fully2_weight_inc, weights['fully2_weight'], momW, wc, learning_rate, gradients['fully2_weight_grad'])\n",
    "        weights['fully2_weight'] = weights['fully2_weight'] + fully2_weight_inc\n",
    "        fully2_bias_inc = get_new_weight_inc(\n",
    "            fully2_bias_inc, weights['fully2_bias'], momW, wc, learning_rate, gradients['fully2_bias_grad'])\n",
    "        weights['fully2_bias'] = weights['fully2_bias'] + fully2_bias_inc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:3.310e-01, accuracy:0.897000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, _ = feedforward_backprop(test_data, test_label, weights)\n",
    "print('loss:%0.3e, accuracy:%f\\n' % (loss, accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1.0,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1.0,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16.0,
    "lenType": 16.0,
    "lenVar": 40.0
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
